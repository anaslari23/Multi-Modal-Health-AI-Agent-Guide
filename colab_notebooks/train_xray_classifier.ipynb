{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chest X-ray Classifier Training - Pneumonia Detection\n",
    "\n",
    "This notebook trains a ResNet50 model to detect pneumonia from chest X-ray images.\n",
    "\n",
    "**Dataset**: ~1,060 chest X-ray images (NORMAL vs PNEUMONIA)\n",
    "\n",
    "**Architecture**: ResNet50 with transfer learning\n",
    "\n",
    "**Runtime**: ~20-30 minutes with GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q torch torchvision pillow matplotlib scikit-learn opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "import torch\n",
    "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Upload Dataset\n",
    "\n",
    "**Instructions**:\n",
    "1. Zip your `chest_xray` folder on your Mac:\n",
    "   ```bash\n",
    "   cd /Users/anaslari/Desktop/doctor_online/datasets\n",
    "   zip -r chest_xray.zip chest_xray/\n",
    "   ```\n",
    "2. Upload `chest_xray.zip` to Colab using the file browser\n",
    "3. Run the cell below to extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract dataset\n",
    "!unzip -q chest_xray.zip\n",
    "!ls -la chest_xray/chest_xray/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG: Print directory structure to find where the images are\n",
    "import os\n",
    "print('Current directory:', os.getcwd())\n",
    "print('\nListing chest_xray directory:')\n",
    "ls -lh /Users/anaslari/Desktop/doctor_online/datasets/chest_xray | head -20 -R chest_xray | head -20\n",
    "\n",
    "# Find the train directory automatically\n",
    "found_train = False\n",
    "for root, dirs, files in os.walk('chest_xray'):\n",
    "    if 'train' in dirs:\n",
    "        train_path = os.path.join(root, 'train')\n",
    "        print(f'\nFOUND TRAIN DIRECTORY AT: {train_path}')\n",
    "        found_train = True\n",
    "        # Set the data_dir to the parent of train\n",
    "        data_dir = Path(root)\n",
    "        break\n",
    "\n",
    "if not found_train:\n",
    "    print('\n\u274c COULD NOT FIND TRAIN DIRECTORY! Did the unzip finish?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Robustly find the dataset directory\n",
    "data_dir = None\n",
    "possible_paths = [\n",
    "    'chest_xray/chest_xray',\n",
    "    'chest_xray',\n",
    "    'chest_xray/train',\n",
    "    './train'\n",
    "]\n",
    "\n",
    "# Check known paths\n",
    "for p in possible_paths:\n",
    "    if os.path.exists(os.path.join(p, 'train')):\n",
    "        data_dir = Path(p)\n",
    "        print(f'\u2705 Found dataset at: {data_dir}')\n",
    "        break\n",
    "\n",
    "# If not found, search recursively\n",
    "if data_dir is None:\n",
    "    print('\u26a0\ufe0f Dataset not found in standard paths. Searching recursively...')\n",
    "    for root, dirs, files in os.walk('.'):\n",
    "        if 'train' in dirs:\n",
    "            # Verify it has the right classes\n",
    "            train_path = os.path.join(root, 'train')\n",
    "            if os.path.exists(os.path.join(train_path, 'NORMAL')):\n",
    "                data_dir = Path(root)\n",
    "                print(f'\u2705 Found dataset at: {data_dir}')\n",
    "                break\n",
    "\n",
    "if data_dir is None:\n",
    "    print('\u274c ERROR: Could not find dataset! Please check the unzip output.')\n",
    "    # List current directory to help debug\n",
    "    lsof -i :8000 -R | head -20\n",
    "else:\n",
    "    train_dir = data_dir / 'train'\n",
    "    val_dir = data_dir / 'val'\n",
    "    test_dir = data_dir / 'test'\n",
    "    \n",
    "    # Count images\n",
    "    def count_images(directory):\n",
    "        normal = len(list((directory / 'NORMAL').glob('*.jpeg')))\n",
    "        pneumonia = len(list((directory / 'PNEUMONIA').glob('*.jpeg')))\n",
    "        return normal, pneumonia\n",
    "\n",
    "    train_normal, train_pneumonia = count_images(train_dir)\n",
    "    val_normal, val_pneumonia = count_images(val_dir)\n",
    "    test_normal, test_pneumonia = count_images(test_dir)\n",
    "\n",
    "    print(\"\\nDataset Statistics:\")\n",
    "    print(f\"Train: {train_normal} NORMAL, {train_pneumonia} PNEUMONIA\")\n",
    "    print(f\"Val: {val_normal} NORMAL, {val_pneumonia} PNEUMONIA\")\n",
    "    print(f\"Test: {test_normal} NORMAL, {test_pneumonia} PNEUMONIA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "def show_samples(directory, n=4):\n",
    "    # Get image lists\n",
    "    normal_images = list((directory / 'NORMAL').glob('*.jpeg'))\n",
    "    pneumonia_images = list((directory / 'PNEUMONIA').glob('*.jpeg'))\n",
    "    \n",
    "    # Adjust n if there aren't enough images\n",
    "    n_normal = min(n, len(normal_images))\n",
    "    n_pneumonia = min(n, len(pneumonia_images))\n",
    "    n_display = max(n_normal, n_pneumonia)\n",
    "    \n",
    "    if n_display == 0:\n",
    "        print('No images found!')\n",
    "        return\n",
    "    \n",
    "    fig, axes = plt.subplots(2, n_display, figsize=(15, 6))\n",
    "    if n_display == 1:\n",
    "        axes = axes.reshape(2, 1)\n",
    "    \n",
    "    # NORMAL samples\n",
    "    for i in range(n_display):\n",
    "        if i < n_normal:\n",
    "            img_path = random.choice(normal_images)\n",
    "            img = Image.open(img_path)\n",
    "            axes[0, i].imshow(img, cmap='gray')\n",
    "            axes[0, i].set_title('NORMAL')\n",
    "        axes[0, i].axis('off')\n",
    "    \n",
    "    # PNEUMONIA samples\n",
    "    for i in range(n_display):\n",
    "        if i < n_pneumonia:\n",
    "            img_path = random.choice(pneumonia_images)\n",
    "            img = Image.open(img_path)\n",
    "            axes[1, i].imshow(img, cmap='gray')\n",
    "            axes[1, i].set_title('PNEUMONIA')\n",
    "        axes[1, i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_samples(train_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Prepare Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Data augmentation for training\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# No augmentation for validation/test\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=train_transforms)\n",
    "val_dataset = datasets.ImageFolder(val_dir, transform=val_transforms)\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=val_transforms)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"Class names: {train_dataset.classes}\")\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "# Load pretrained ResNet50\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# Freeze early layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace final layer for binary classification\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(num_features, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(512, 2)  # 2 classes: NORMAL, PNEUMONIA\n",
    ")\n",
    "\n",
    "# Move to GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"Model on device: {device}\")\n",
    "print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.5)\n",
    "\n",
    "# Training function\n",
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in tqdm(loader, desc='Training'):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    return running_loss / len(loader), 100. * correct / total\n",
    "\n",
    "# Validation function\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc='Validation'):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    return running_loss / len(loader), 100. * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train for 10 epochs\n",
    "num_epochs = 10\n",
    "best_val_acc = 0.0\n",
    "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "print(\"\ud83d\ude80 Starting training...\\n\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
    "    \n",
    "    # Update scheduler\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # Save history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), 'best_xray_model.pth')\n",
    "        print(\"\u2705 Best model saved!\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "print(f\"\\n\ud83c\udf89 Training complete! Best validation accuracy: {best_val_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Loss\n",
    "ax1.plot(history['train_loss'], label='Train Loss')\n",
    "ax1.plot(history['val_loss'], label='Val Loss')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training and Validation Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# Accuracy\n",
    "ax2.plot(history['train_acc'], label='Train Acc')\n",
    "ax2.plot(history['val_acc'], label='Val Acc')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy (%)')\n",
    "ax2.set_title('Training and Validation Accuracy')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "model.load_state_dict(torch.load('best_xray_model.pth'))\n",
    "\n",
    "# Evaluate\n",
    "test_loss, test_acc = validate(model, test_loader, criterion, device)\n",
    "print(f\"\\n\ud83d\udcca Test Set Results:\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = outputs.max(1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "# Classification report\n",
    "print(\"\\n\ud83d\udccb Classification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=['NORMAL', 'PNEUMONIA']))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(8, 6))\n",
    "import seaborn as sns\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['NORMAL', 'PNEUMONIA'],\n",
    "            yticklabels=['NORMAL', 'PNEUMONIA'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample predictions\n",
    "import random\n",
    "\n",
    "def show_predictions(model, dataset, n=8):\n",
    "    model.eval()\n",
    "    indices = random.sample(range(len(dataset)), n)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for i, idx in enumerate(indices):\n",
    "        image, label = dataset[idx]\n",
    "        \n",
    "        # Predict\n",
    "        with torch.no_grad():\n",
    "            output = model(image.unsqueeze(0).to(device))\n",
    "            _, pred = output.max(1)\n",
    "        \n",
    "        # Denormalize image for display\n",
    "        img = image.permute(1, 2, 0).numpy()\n",
    "        img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "        img = np.clip(img, 0, 1)\n",
    "        \n",
    "        # Plot\n",
    "        axes[i].imshow(img)\n",
    "        true_label = dataset.classes[label]\n",
    "        pred_label = dataset.classes[pred.item()]\n",
    "        color = 'green' if true_label == pred_label else 'red'\n",
    "        axes[i].set_title(f'True: {true_label}\\nPred: {pred_label}', color=color)\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_predictions(model, test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save complete model\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'class_names': train_dataset.classes,\n",
    "    'best_val_acc': best_val_acc,\n",
    "}, 'xray_classifier_complete.pth')\n",
    "\n",
    "print(\"\u2705 Model saved to xray_classifier_complete.pth\")\n",
    "print(\"\\nDownload this file and copy to:\")\n",
    "print(\"/Users/anaslari/Desktop/doctor_online/mm-hie-backend/app/modules/imaging/models/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83c\udf89 Training Complete!\n",
    "\n",
    "### Next Steps:\n",
    "1. Download `xray_classifier_complete.pth`\n",
    "2. Copy to: `mm-hie-backend/app/modules/imaging/models/`\n",
    "3. Update `imaging_model.py` to load this model\n",
    "4. Test with chest X-ray uploads!\n",
    "\n",
    "### Expected Performance:\n",
    "- Accuracy: ~90-95% (typical for this dataset)\n",
    "- Sensitivity (Pneumonia detection): ~95%+\n",
    "- Specificity (Normal detection): ~85%+\n",
    "\n",
    "### Model Info:\n",
    "- Base: ResNet50 (pretrained on ImageNet)\n",
    "- Classes: 2 (NORMAL, PNEUMONIA)\n",
    "- Parameters: ~25M\n",
    "- Size: ~100MB"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}