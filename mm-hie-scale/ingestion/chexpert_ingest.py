import argparse
import logging
from pathlib import Path
from typing import Optional

from common_normalizer import (
    build_episode,
    deidentify_record,
    write_episode_json,
    ensure_directory,
)


logger = logging.getLogger(__name__)


def configure_logging(level: str) -> None:
    numeric_level = getattr(logging, level.upper(), logging.INFO)
    logging.basicConfig(
        level=numeric_level,
        format="%(asctime)s [%(levelname)s] %(name)s - %(message)s",
    )


def run_chexpert_ingestion(
    raw_root: Path,
    processed_root: Path,
    max_episodes: Optional[int] = None,
) -> None:
    """Ingest CheXpert into canonical episodes.

    Typical pattern: one episode per study/series with imaging findings as labels
    (e.g. CheXpert competition labels mapped to SNOMED/ICD-10).
    """
    raw_chexpert_root = raw_root / "chexpert"
    output_dir = processed_root / "chexpert"
    ensure_directory(output_dir)

    if not raw_chexpert_root.exists():
        logger.warning("Raw CheXpert root does not exist: %s", raw_chexpert_root)
        return

    logger.info("Starting CheXpert ingestion from %s to %s", raw_chexpert_root, output_dir)

    episodes_processed = 0

    # Placeholder: no episodes are generated by default. Wire in the CheXpert
    # CSV (e.g. train.csv, valid.csv) and map label columns to SNOMED/ICD-10
    # codes before building episodes.
    placeholder_episode_list = []  # type: ignore[var-annotated]

    for episode_meta in placeholder_episode_list:
        if max_episodes is not None and episodes_processed >= max_episodes:
            break

        try:
            episode_id = str(episode_meta["episode_id"])
            notes = episode_meta.get("notes", [])
            labs = episode_meta.get("labs", [])
            vitals = episode_meta.get("vitals", [])
            imaging = episode_meta.get("imaging", [])
            labels = episode_meta.get("labels", [])
            timestamps = episode_meta.get("timestamps", {})

            notes = [deidentify_record(n) for n in notes]
            imaging = [deidentify_record(i) for i in imaging]

            episode = build_episode(
                episode_id=episode_id,
                notes=notes,
                labs=labs,
                vitals=vitals,
                imaging=imaging,
                labels=labels,
                timestamps=timestamps,
            )
            write_episode_json(episode, output_dir)
            episodes_processed += 1
        except Exception:
            logger.exception("Failed to process CheXpert episode meta: %s", episode_meta)

    logger.info("Finished CheXpert ingestion, episodes=%d", episodes_processed)


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Ingest CheXpert into canonical episodes")
    parser.add_argument("--raw-root", type=Path, default=Path("raw"), help="Root of raw data lake (expects raw/chexpert)")
    parser.add_argument(
        "--processed-root",
        type=Path,
        default=Path("processed"),
        help="Root of processed data lake (writes processed/chexpert)",
    )
    parser.add_argument("--max-episodes", type=int, default=None, help="Optional cap on number of episodes")
    parser.add_argument("--log-level", type=str, default="INFO", help="Logging level (DEBUG, INFO, WARNING, ERROR)")
    return parser.parse_args()


def main() -> None:
    args = parse_args()
    configure_logging(args.log_level)
    try:
        run_chexpert_ingestion(
            raw_root=args.raw_root,
            processed_root=args.processed_root,
            max_episodes=args.max_episodes,
        )
    except Exception:
        logger.exception("Unhandled exception in CheXpert ingestion")
        raise


if __name__ == "__main__":
    main()
